\documentclass[final]{jneurosci}


%
% Packages
%
\usepackage[colorinlistoftodos,prependcaption,textsize=tiny]{todonotes}
\usepackage{hyperref}
\usepackage{natbib}
\usepackage{nameref}
\usepackage[]{algorithm2e}


%
% Parameters
% (guidelines of The Journal of Neuroscience can be found at http://www.jneurosci.org/site/misc/ifa_organization.xhtml)
%
\Year{2016}
%\nolinenumbers


%
% The document
%
\begin{document}


%
% Title
%
\title{Intracranial \& DNN}
\author{Ilya \surname{Kuzovkin}$^{1,\ast}$, Juan \surname{Vidal}$^{2}$, Raul \surname{Vicente}$^{1}$ and Jaan \surname{Aru}$^{1}$}
\address{$^{1}$Computational Neuroscience Lab, Institute of Computer Science, Universtity of Tartu, Estonia\\$^{2}$???}
\corres{$^{\ast}$Corresponding author. E-mail: ilya.kuzovkin@gmail.com}


%
% Abstract
%
\begin{abstract}
We did lots of cool stuff.
\vskip1pt
\end{abstract}
\maketitle


%
% Significance Statement
% (120 words maximum)
%
\section{Significance Statement}


%
% Introduction
% (650 words maximum, including citations)
%
\section{Introduction}
Visual object recognition in humans is mediated by a hierarchy of transformations across the ventral visual stream [DiCarlo 2012]. Intriguingly, these transformations are quite similar to the hierarchy of transformations learned by deep convolutional neural networks (DCNN) trained on natural images. For example, it has been shown that DCNN provide the best model out of a wide range of neuroscientific and computer vision models for the neural representation of visual images in high-level visual cortex of monkeys [Yamins 2014] and humans [Khaligh-Razavi 2014]. Other papers have demonstrated a direct correspondence between the hierarchy of the human visual areas and layers of the DCNN [\citep{gucclu2015deep}, Seibert, 2016, Cichy, 2016]. Moreover, recent work has demonstrated with millisecond resolved magnetoencephalography (MEG) that deeper layers of the DCNN predict later brain signals [Cichy, 2016]. Taken together these results have led to the conclusion that the DCNN provide a good model for understanding visual processing in the primate brain  [Kriegeskorte 2015, Yamins 2016].

Another and so far a completely separate line of research has intensively studied the electrophysiological correlates of feedforward and feedback visual processing (see Roelfsema, 2006; Bastos 2012 for reviews).
Based on the recent research in monkeys and humans the feedforward activity seems to be carried by the signals in the gamma frequency range whereas the alpha-beta band has been shown to reflect feedback signals from higher visual areas [van kerkoerle 2014, Bastos 2015, Michalareas 2016].  

In this work we bring these separate research lines together. As the DCNN is a feedforward network and signals in the gamma frequency range are thought to reflect feedforward processing, one would expect that signals in the gamma range can be modeled by the DCNN. A complementary prediction is that as signals in the alpha-beta band are thought to reflect feedback processing, there should be no such correspondence between the DCNN and activity at the alpha-beta band. Finally, feedforward activity is thought to be finished in ca 200-250 milliseconds after stimulus onset [e.g. DiCarlo 2012], hence one should not find a correspondence between the DCNN and gamma in a later time window.

The aim of the present study is to evaluate these hypotheses. To this end we capitalized on direct intracranial recordings from 109 patients and a total of >12000 electrodes. The spatial and temporal precision of the intracranial recordings allowed us to ask whether the early gamma activity in lower and higher visual areas corresponds to the lower and higher layers of the DCNN, respectively.  


%
% Materials and Methods
%
\section{Materials and Methods}


\subsection{Patients and Recordings}

XXX patients (xx female, group mean age xxx years) with drug-resistant partial epilepsy and candidates for surgery were considered in this study and recruited from Neurological Hospitals in Grenoble and Lyon. Because the location of the epileptic focus could not be identified using non-invasive methods; the patients underwent intracerebral recordings by means of stereotactically implanted multi-lead electrodes (SEEG). Recording sites were selected solely according to clinical indications, with no reference to the current experiment. All the patients had previously given their informed consent to participate in this experiment and research recordings were approved by the National French Science Ethical Committee (CPPRB). All had normal or corrected to normal vision.

\subsubsection{Electrode Implantation}

Eleven to 15 semi-rigid electrodes were implanted per patient in cortical areas which varied depending on the suspected origin of their seizures. Each electrode had a diameter of 0.8 mm and was comprised of 10 or 15 contacts of 2 mm length, depending on the target region, 1.5 mm apart (Dixi, Besançon, France). Therefore, various medial and lateral cortical areas were evaluated for each patient (see Figure 1B), the coordinates of each electrode contact with their stereotactic scheme was measured (in the Talairach coordinate system). The coordinates were used to anatomically localize the contacts using the proportional atlas of Talairach and Tournoux (Talairach et al., 1993), after a linear scale adjustment to correct size differences between the patient’s brain and the Talairach model. These locations were further confirmed by overlaying a post-implantation CT scan (showing contact sites) with a pre-implantation structural MRI with VOXIMR (IVS Solutions, Chemnitz, Germany), allowing direct visualization of contact sites relative to brain anatomy.

These patients voluntarily participated in a series of short experiments to identify local functional responses at the recorded sites. The results presented here were obtained from a test exploring visual recognition. All data were recorded using approximately 120 implanted depth electrode contacts per patient with a sampling rate of 512 Hz. Data were obtained in a total of xxxx recording sites.

\subsubsection{Stimuli and Task}
\label{sec:stimuli-and-task}

The visual recognition task lasted about 15 min. Patients were instructed to press a button each time a picture of a fruit appeared on screen (visual oddball paradigm). Non-target stimuli consisted of pictures of objects of eight possible categories: houses, faces, animals, scenes, tools, pseudowords, consonant strings, and scrambled images. The last three categories were not included in this analysis. All stimuli had the same average luminance except for pseudowords and consonant strings which consisted of a white letter string on a black background. All categories were presented within an oval aperture (Figure \ref{fig:image-of-each-category}).
\begin{figure}[h]
    \centering
    \includegraphics[width=1.0\linewidth]{images/images-from-6-categories.png}
    \caption{Example of a stimulus image from each of 6 categories.}
    \label{fig:image-of-each-category}
\end{figure}
Stimuli were presented for a duration of 200 ms every 1000–1200 ms in series of 5 pictures interleaved by 3-s pause periods during which patients could freely blink. Patients reported the detection of a target through a right-hand button press and were given feedback of their performance after each report. A 2-s delay was placed after each button press before presenting the follow-up stimulus in order to avoid mixing signals related to motor action with signals from stimulus presentation. Importantly, we only analyzed here the neural responses to all non-target stimuli that did not elicit a button press. Each visual category was presented 50 times during the whole experiment.

\subsection{Data Analysis}

\subsubsection{Signal preprocessing}

bipolar, 

artifacts, 

epochs

time ; to study the specificity in time we also ran the same analysis in two other time windows

As the DCNN is a feedforward network, it is parsimonious to expect it should correspond to neural signals ... Di Carlo. We chose our time window to be 50-250 ms based on previous work (Cichy, Yamins) C: The peak latencies of the correlation time course were between ca 100 and 160 ms.; Y: averaging spike counts in the period 70–170 ms after stimulus presentation

Spectral analysis

To quantify signal power modulations across time and frequency we used standard time–frequency (TF) wavelet decomposition (Tallon-Baudry et al., 1996). The signal $s(t)$ is convoluted with a complex Morlet wavelet $w(t, f_0)$, which has Gaussian shape in time $(\sigma t)$ and frequency $(\sigma f)$ around a central frequency $f_0$ and defined by: yes with $\sigma f = 1/2 \pi \sigma t$ and a normalization factor yes 

Throughout this study we used a wavelet family with cycle number set to 7 (i.e., $\frac{f_0}{\sigma f} = 7$). The square norm of the convolution results in a time-varying representation of spectral power, given by: $P(t, f_0) = |w(t, f_0) × s(t)|^2$.




\subsubsection{Statistical Evaluation of responsiveness}

We assessed neural responsiveness of the electrode in a given frequency. For that we compared the post-stimulus activity to its average baseline power level with a Wilcoxon signed-rank test for matched-pairs. All p-values from this test were corrected for multiple comparisons across all electrodes with a false discovery rate (FDR) procedure (Genovese et al., 2002). From the electrodes that survived this test only the ones with a positive ......................

\subsection{Mapping Electrode Activity to DCNN}
In the recent studies on comparing activity of the visual cortex to the activity of DCNN we can distingush two methods: one is based on linear regression models that predict neural response form DCNN activations \citep{gucclu2015deep} and the second is based on representation dissimilarity analysis \citep{kriegeskorte2008representational} and compares distances between stimuli in the neural response space with the distances in DCNN activation space \citep{cichy2016deep}. In this section we describe both methods in the context of our dataset.

\subsubsection{Extracting DCNN activations}
Both of the mapping methods perform computations on the activation values of the nodes of DCNN. To obtain the activations we take AlexNet \citep{krizhevsky2012imagenet} pretrained on ImageNet \citep{ILSVRC15}, let it classify the same images that were presented to the test subjects (see section ``\nameref{sec:stimuli-and-task}" and Figure \ref{fig:image-of-each-category}) and store all the activation values of the network for each of the images.

\subsubsection{Linear Mapper}
For each probe $p$ we train 9 linear models $\text{LM}^l_p$ where $p$ is the index of the probe and $l$ is the number of the layer of DCNN. Each model is a function that predicts repsonse of a probe from the activations of a layer:
$$\text{LM}^l_p: \mathbb{R}^{|\mathbf{a}_l|} \rightarrow \mathbb{R},$$
where $|\mathbf{a}_l|$ is the cardinality of the vector of activations of layer $l$. We are in the regime where the number of samples $n=269$ is orders of magnitude smaller than the number of features $m_l$ for most of the layers. For that reason we strongly regularize our models with L2 penalty. The regularization parameter $\alpha$ is estimated with 10-fold cross-validation: the $\alpha$ that results in highest $R^2$ score is fixed to be used in the final model. Once $\alpha$ is selected we reshuffle the order of samples in the dataset and predict all $n$ responses via another round of 10-fold cross-validation. We measure Spearman's rank correlation coefficient $\rho_{\text{LM}^l_p}$ between the true and predicted neural responses of the probe and the correlation significance $\text{p-value}_{\text{LM}^l_p}$ for each of the models. Since the number of samples $n=269$ is small, the performance estimation procedure is unstable under different reshufflings of the dataset. To obtain stable results we repeat the performance estimation procedure 7 times and consider a model to have predictive power only if in majority of runs (4 out of 7) the significance level is below threshold $$\text{p-value}_{\text{LM}^l_p} \leq 0.00001.$$ If the inequality holds we assign the mapping score for each of the layers by taking the average $\rho_{\text{LM}^l_p}$ over 7 runs. This concludes the mapping procedure for one probe (see Algorithm \ref{alg:linear-mapper} for pseudocode).

\vspace{1em}
\begin{algorithm}[H]
    \KwData{Feature matrices $\mathbf{X}^l$ or size $n \times |\mathbf{a_l}|$ for each of the layers $l = 0\ldots8$ and a vector of true neural responses $\mathbf{y}_p$}
    \KwResult{Distributed mapping of probe $p$ to 9 layers of DCNN}
    \State{Regularization parameter $\alpha \gets$ scan range of values with cross-validation and pick $\alpha$ that gives highest $R^2$}
    
    \For{$l = 0\ldots8$}{
        \State{significant\_counter $\gets 0$}\;
        \For{$r = 1\ldots7$}{
            \State{Train $\text{LM}_r$ on $\mathbf{X}^l$ to predict $\mathbf{y}_p$}\;
            \State{$\hat{\mathbf{y}_p} \gets$ 10-fold cross-validation of $\text{LM}_r$ on $\mathbf{X}^l$}\;
            \State{$\rho_{\text{LM}_r}, \text{p-value}_{\text{LM}_r} \gets \text{Spearman}(\mathbf{y}_p, \hat{\mathbf{y}_p})$}
            
            \If {$\text{p-value}_{\text{LM}_r} \leq 0.00001$}{
                \State{significant\_counter $\gets$ significant\_counter $+ 1$}
            }
        }
        \eIf {significant\_counter $\geq 4$}{
            \State{$\text{score}_l \gets \displaystyle\frac{1}{7}\sum^7_r{\rho_{\text{LM}_r}}$}
        }{
            \State{$\text{score}_l \gets 0$}
        }
    }
    \Return $\text{score}_0\ldots\text{score}_8$\;
    \ 
 
\caption{Distributed mapping of a probe to DCNN layers based on Spearman's $\rho$ between true neural responses of a probe and the ones predicted by a linear regression model.}
\label{alg:linear-mapper}
\end{algorithm}
\vspace{1em}

The mapping procedure outlined in Algorithm \ref{alg:linear-mapper} is repeated for each of the probes separately and provides layer assignment score for each (probe, layer) pair.

\subsubsection{RSA Based Mapper}
Representational similarity analysis (RSA) for a single probe $p$ consists of two major steps.

First is to build a representation dissimilarity matrix (RDM) of size \emph{number of stimuli} $\times$ \emph{number of stimuli} (in our case $269 \times 269$) for each of the features spaces. Given a matrix $\text{RDM}_\text{feature space}$ a value $\text{RDM}^{ij}_\text{feature space}$ in the $i$th row and $j$th column of the matrix shows the euclidean distance between the vectors $\mathbf{v}_i$ and $\mathbf{v}_j$ that represent respectively images $i$ and $j$ in that particular feature space. In our case there are 10 different features spaces (see Table \ref{tab:feature-spaces}) in which a stimulus (an image) can be represented: the original pixel space, 8 feature spaces for each of the layers of the DCNN and one space where an image is represented by the preprocessed neural response of probe $p$.

The second step is to compare the $\text{RDM}_p$ for neural response with RDMs for layers of DCNN. The similarity measure we use is Spearman's rank correlation on [matrix | image | both]:
$$\text{score}_\text{layer} = \text{Spearman}(\text{RDM}_p, \text{RDM}_\text{layer}).$$
\todo[inline]{describe how we obtain the score, to be written later when decided which score(s) we'll use}
As a result of comparing $\text{RDM}_p$ with every other $\text{RDM}_*$ we obtain 9 scores: $\text{score}_\text{pixels}\ldots\text{score}_\texttt{fc8}$ that serve as distributed mapping of probe $p$ to the layers of DCNN.

\begin{table}[h]
    \centering
    \begin{tabular}{l|r|c}
        \textbf{Space} & \textbf{Dimensionality} & RDM \\ \hline
        Pixels of an image & 72,234 & $\text{RDM}_\text{pixels}$ \\
        convolutional layer 1 & 300,000 & $\text{RDM}_\texttt{conv1}$ \\
        convolutional layer 2 & & $\text{RDM}_\texttt{conv2}$\\
        convolutional layer 3 & & $\text{RDM}_\texttt{conv3}$ \\
        convolutional layer 4 & & $\text{RDM}_\texttt{conv4}$ \\
        convolutional layer 5 & & $\text{RDM}_\texttt{conv5}$ \\
        fully connected layer 6 & & $\text{RDM}_\texttt{fc6}$ \\
        fully connected layer 7 & 4096 & $\text{RDM}_\texttt{fc7}$ \\
        fully connected layer 8 & 1000 & $\text{RDM}_\texttt{fc8}$ \\
        Neural activity of a probe & 1 & $\text{RDM}_p$
    \end{tabular}
    \caption{The list and the properties of 10 possible feature representations of an image.}
    \label{tab:feature-spaces}
\end{table}




\subsubsection{Permutation test}
When comparing RDMs we cannot rely on the assumption that the SciPy~\citep{scipy} has.
\todo[inline]{hard time to explain why we did not do that in the linear mapper case}
To estimate statistical significance of a score we created a surrogate data set by permuting single-trial amplitude values from two conditions prior to estimating the score. We repeated this procedure $100,000$ times to create a surrogate set and compared it to the original score. If the score was bigger than the respective maximal value of the surrogate set then we considered the index to be significantly different at $p \le 0.00001$.


%
% Results
%
\section{Results}

First, we determined which electrodes were visually responsive in the high gamma range, ie showed enhanced GBR responses to the set of images (see methods). This resulted in 549 probes. We then investigated how the responses of these electrodes are captured by DCNN. In particular, we used RSA to compare the representational geometry of different DCNN layers and these selective probes (see Figure 1A).

TODO: Figure 1 should give a general overview of the method, eg http://www.nature.com/articles/srep27755/figures/2

In the high gamma band we observed ...(Figure 1B - here show all BA areas for early high gamma)

As explained in the introduction, we expected the early gamma activity in lower and higher visual areas to correspond to the lower and higher layers of the DCNN, respectively. \todo[inline]{That sounds too defeaty, I'd write something like "we wanted to find which time/freq is best for DCNN, from [ref, ref] we had a clue that is should be ealry high gamma which comes from the theory that the brain does blabla! [ref], and then... we did the experiments… and tada! low gamma is also, theta is also, later time is also — it means tadadada! can you imagine that?!", which sends out a stement people could talk about} To test this hypothesis we now turned to other frequency bands and to other time windows with a prediction that the DCNN should not explain the responses there. 

\subsection{Correlation to DCNN is not specific to early high gamma responses}

However, as evidenced on Figure X, some other frequency bands and all time windows also showed a qualitatively similar correlation profile

todo: figure X; show 5 freqs x 3 times plots for 5 visual areas, ie drop all non-visual areas from this plot 

In particular ...... - here we need to quantify these things. from the plots it seems that high gamma and theta are the best, but how to show it with numbers?

\subsection{Correlation to DCNN is specific to visual areas}

We observed that the mapping to DCNN was not specific in time and frequency. However, the mapping was consistently observed only in visual areas over all time-frequency combinations (quantify)

\section{Discussion}

In the current work we investigated the mapping of deep convolutional neural networks to human gamma band responses as measured with intracranial recordings. Although based on previous work (cit) one would expect there to be a specific mapping between high gamma and DCNN, we found correspondences not only in the high gamma frequency, but in other frequencies too. Also, as DCNN is a feedforward network and feedforward processing is thought to happen early (cit), there should be mapping early, not late. However, this was also not true. We next discuss these two dimensions.

\subsection{Correlation to DCNN is unspecific in frequency}

spectral leakage? no, but broadband all across the frequencies (Kai Miller 2009a b ). In principle could be solved with PCA, but this is computationally infeasible in our case (is this true? Ilya, read the section DISCRETE SPECTRAL ANALYSIS AND DECOMPOSITION here http://www.jneurosci.org/content/29/10/3132.long.

but not only broadband - important increases in theta. this is a longer discussion point why theta. (it is also one of the main original findings, but we will be screwed by these guys at SfN whose poster copied to you)

\subsection{Correlation to DCNN is unspecific in time}

First, could this be smearing or leaking of the early activity to other timewindows - not likely because even at the lowest 70 Hz the wavelet length is only 86 ms. 

In a directly relevant previous work Cichy and colleagues compared DCNN representations to millisecond resolved magnetoencephalography (MEG) data from humans [Cichy 2016]. There was a positive correlation between the layer number of the DCNN and the peak latency of the correlation time course between the respective DCNN layer and MEG signals. In other words, deeper layers of the DCNN predicted later brain signals. The peak latencies of the correlation time course were between ca 100 and 160 ms. The correspondence between the layers of the DCNN and the peak latencies was far from perfect as “for the first four DNN layers the relationship was weak and negative”. On the other hand, “for the last four layers the relationship was strongly positive” [Cichy 2016]. As evidenced on Figure 3 in [Cichy 2016], the correlation between DCNN and MEG activity peaked between ca 100 and 160 ms for all layers, but significant correlation persisted well beyond that time-window. Hence, these previous results agree with the current ones in showing that  ...

What do these results mean for the idea that DCNN = feedforward processing?

\subsection{Correlation to DCNN is specific to visual areas}

Given that the mapping to DCNN was not specific in time and frequency, the specificity in space is even more striking.

%
%  Linear Mapper per image
%
\subsection{Linear Mapper}

See Figures \ref{fig:lp-resppositive}, \ref{fig:lp-responsive}.

\begin{figure}[h]
\centering
\includegraphics[width=0.7\linewidth]{images/lp_meangamma_bipolar_noscram_artif_brodmann_resppositive.png}
\caption{Linear mapper on 554 positively responsive probes. Only probes that were predictable with significance of 0.00001 contributed to this plot.}
\label{fig:lp-resppositive}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=0.7\linewidth]{images/lp_meangamma_bipolar_noscram_artif_responsive_brodmann.png}
\caption{Mapping based on Linear Predictor on 9093 responsive probes.  Only probes that were predictable with significance of 0.00001 contributed to this plot.}
\label{fig:lp-responsive}
\end{figure}


%
%  RSA per image
%
\subsection{RSA Mapper}

See Figures \ref{fig:rsa-permatrix-permutaton}, \ref{fig:rsa-perimage-threshold}, \ref{fig:rsa-perimage-permutaton}.

\begin{figure}[h]
\centering
\includegraphics[width=0.7\linewidth]{images/rsa_meangamma_bipolar_noscram_artif_brodmann_resppositive_euclidean_matrixpermfiltered.png}
\caption{Mapping based on RSA on 554 positively responsive probes. Similarity score is computed per-matrix with no threshold. Results are filtered by significance levels obtained from the permutation test. Only probes with p-values $\leq 0.00001$ contributed to this plot.}
\label{fig:rsa-permatrix-permutaton}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=0.7\linewidth]{images/rsa_meangamma_bipolar_noscram_artif_brodmann_resppositive_euclidean_image00001.png}
\caption{Mapping based on RSA on 554 positively responsive probes. Similarity score is computed per-image with p-value threshold of $0.00001$.}
\label{fig:rsa-perimage-threshold}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=0.7\linewidth]{images/not-yet.png}
\caption{Mapping based on RSA on 554 positively responsive probes. Similarity score is computed per-image with no threshold. Results are filtered by significance levels obtained from the permutation test. Only probes with p-values $\leq 0.00001$ contributed to this plot.}
\label{fig:rsa-perimage-permutaton}
\end{figure}


%
%  Single probe plots (no aggregating of scores)
%
\subsection{Single plots}
\todo[inline]{To be repeated on only positively responsive probes.}

\subsubsection{Variance Explained}
See Figures \ref{fig:single_plots_variance_explained}, See Figures \ref{fig:single_plots_variance_explained_hist}

\begin{figure}
\centering
\includegraphics[width=0.3\linewidth]{images/xmni_yvarexp_perprobe_permatrix_nothresh_layer0.png}
\includegraphics[width=0.3\linewidth]{images/xmni_yvarexp_perprobe_permatrix_nothresh_layer1.png}
\includegraphics[width=0.3\linewidth]{images/xmni_yvarexp_perprobe_permatrix_nothresh_layer2.png}
\includegraphics[width=0.3\linewidth]{images/xmni_yvarexp_perprobe_permatrix_nothresh_layer3.png}
\includegraphics[width=0.3\linewidth]{images/xmni_yvarexp_perprobe_permatrix_nothresh_layer4.png}
\includegraphics[width=0.3\linewidth]{images/xmni_yvarexp_perprobe_permatrix_nothresh_layer5.png}
\includegraphics[width=0.3\linewidth]{images/xmni_yvarexp_perprobe_permatrix_nothresh_layer6.png}
\includegraphics[width=0.3\linewidth]{images/xmni_yvarexp_perprobe_permatrix_nothresh_layer7.png}
\includegraphics[width=0.3\linewidth]{images/xmni_yvarexp_perprobe_permatrix_nothresh_layer8.png}
\caption{Single electrode variance explained. X - sagittal MNI coordinate, Y - variance explained.}
\label{fig:single_plots_variance_explained}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=0.3\linewidth]{images/hist_xmni_yvarexp_perprobe_permatrix_nothresh_layer0.png}
\includegraphics[width=0.3\linewidth]{images/hist_xmni_yvarexp_perprobe_permatrix_nothresh_layer1.png}
\includegraphics[width=0.3\linewidth]{images/hist_xmni_yvarexp_perprobe_permatrix_nothresh_layer2.png}
\includegraphics[width=0.3\linewidth]{images/hist_xmni_yvarexp_perprobe_permatrix_nothresh_layer3.png}
\includegraphics[width=0.3\linewidth]{images/hist_xmni_yvarexp_perprobe_permatrix_nothresh_layer4.png}
\includegraphics[width=0.3\linewidth]{images/hist_xmni_yvarexp_perprobe_permatrix_nothresh_layer5.png}
\includegraphics[width=0.3\linewidth]{images/hist_xmni_yvarexp_perprobe_permatrix_nothresh_layer6.png}
\includegraphics[width=0.3\linewidth]{images/hist_xmni_yvarexp_perprobe_permatrix_nothresh_layer7.png}
\includegraphics[width=0.3\linewidth]{images/hist_xmni_yvarexp_perprobe_permatrix_nothresh_layer8.png}
\caption{Single electrode variance explained. Different colors for different layers. X - sagittal MNI coordinate, Y - hist of variance explained (just counts, not values)}
\label{fig:single_plots_variance_explained_hist}
\end{figure}




\subsubsection{Layer assignment}
See Figures \ref{fig:single_plots_layer_allareas}, \ref{fig:single_plots_layer_visareas}

\begin{figure}
\centering
\includegraphics[width=0.48\linewidth]{images/xmni_ylayer_perprobe_meangamma_bipolar_noscram_artif_responsive_brodmann_all.png}
\includegraphics[width=0.48\linewidth]{images/xmni_ylayer_perprobe_meangamma_bipolar_noscram_artif_responsive_brodmann_all_boxplot.png}
\caption{Single electrode to layer assingment. All areas. Left: single electode data, Right: same data as boxplots. X - sagittal MNI coordinate, Y - layer.}
\label{fig:single_plots_layer_allareas}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=0.48\linewidth]{images/xmni_ylayer_perprobe_meangamma_bipolar_noscram_artif_responsive_brodmann_vis.png}
\includegraphics[width=0.48\linewidth]{images/xmni_ylayer_perprobe_meangamma_bipolar_noscram_artif_responsive_brodmann_vis_boxplot.png}
\caption{Single electrode to layer assingment. Only visual areas. Left: single electode data, Right: same data as boxplots. X - sagittal MNI coordinate, Y - layer.} 
\label{fig:single_plots_layer_visareas}
\end{figure}

%
% Discussion
% (1500 words maximum, including citations)
%
\section{Discussion}


%
% References
%
\section{References}
\bibliographystyle{jneurosci}
\bibliography{intracranialdnn.bib}


%
% Legends
%
\section{Legends}


%
% Illustrations and Tables
%
\section{Illustrations and Tables}


\end{document}
